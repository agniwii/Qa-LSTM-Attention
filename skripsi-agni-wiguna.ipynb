{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8bd584",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-22T09:06:44.672331Z",
     "iopub.status.busy": "2023-12-22T09:06:44.672034Z",
     "iopub.status.idle": "2023-12-22T09:07:06.511116Z",
     "shell.execute_reply": "2023-12-22T09:07:06.510013Z"
    },
    "papermill": {
     "duration": 21.860271,
     "end_time": "2023-12-22T09:07:06.513259",
     "exception": false,
     "start_time": "2023-12-22T09:06:44.652988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model,save_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense,LSTM,Embedding,Input,Lambda,Concatenate,Dropout,Activation,Flatten,Bidirectional,Layer,Attention\n",
    "from keras.optimizers.legacy import Adam, SGD,RMSprop\n",
    "import math\n",
    "from keras.layers import Activation\n",
    "from keras.utils import get_custom_objects, custom_object_scope\n",
    "import keras.backend as K\n",
    "\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57ce7f",
   "metadata": {
    "papermill": {
     "duration": 0.012092,
     "end_time": "2023-12-22T09:07:06.538498",
     "exception": false,
     "start_time": "2023-12-22T09:07:06.526406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> # Data yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f03fcb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:06.564791Z",
     "iopub.status.busy": "2023-12-22T09:07:06.564193Z",
     "iopub.status.idle": "2023-12-22T09:07:06.568822Z",
     "shell.execute_reply": "2023-12-22T09:07:06.567888Z"
    },
    "papermill": {
     "duration": 0.019858,
     "end_time": "2023-12-22T09:07:06.570741",
     "exception": false,
     "start_time": "2023-12-22T09:07:06.550883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@ini data yang dipakai\n",
    "word2vecModel = \"/kaggle/input/question-answering/dataset/word2vec2.model\"\n",
    "dataset_final =  \"/kaggle/input/question-answering/dataset/dataset_final.json\"\n",
    "after_prepro = \"/kaggle/input/question-answering/dataset/after prepro.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b966915d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:06.596362Z",
     "iopub.status.busy": "2023-12-22T09:07:06.596103Z",
     "iopub.status.idle": "2023-12-22T09:07:06.607190Z",
     "shell.execute_reply": "2023-12-22T09:07:06.606167Z"
    },
    "papermill": {
     "duration": 0.026111,
     "end_time": "2023-12-22T09:07:06.609128",
     "exception": false,
     "start_time": "2023-12-22T09:07:06.583017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/question-answering/dataset/word2vec2.model\n",
      "/kaggle/input/question-answering/dataset/dataset_final.json\n",
      "/kaggle/input/question-answering/dataset/after prepro.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4341ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:06.636259Z",
     "iopub.status.busy": "2023-12-22T09:07:06.635989Z",
     "iopub.status.idle": "2023-12-22T09:07:06.673388Z",
     "shell.execute_reply": "2023-12-22T09:07:06.672495Z"
    },
    "papermill": {
     "duration": 0.053379,
     "end_time": "2023-12-22T09:07:06.675318",
     "exception": false,
     "start_time": "2023-12-22T09:07:06.621939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_pad</th>\n",
       "      <th>kandidat</th>\n",
       "      <th>kandidat_pad</th>\n",
       "      <th>bad_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa penyebab turunnya omzet penjualan bunga hi...</td>\n",
       "      <td>Enjang, seorang pedagang bunga, menduga penuru...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apa yang dilakukan pendaki gunung untuk memper...</td>\n",
       "      <td>Bagi yang mempunyai hobi mendaki gunung, merek...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mengapa nama kerta api Empu Jaya akan diganti?</td>\n",
       "      <td>Usut punya usut, nama Empu Jaya dianggap terla...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apa penyebab terjadinya kelangkaan minyak di b...</td>\n",
       "      <td>Penyebabnya adalah kepanikan warga atas rencan...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mengapa Muchyar Yara dihukum?</td>\n",
       "      <td>Dia diberi sanksi lantaran mengkritik kepemimp...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Mengapa mobil otonom menjadi populer?</td>\n",
       "      <td>Mobil otonom menjadi populer karena dapat meni...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Bagaimana cara memilih oli mesin yang tepat?</td>\n",
       "      <td>Beberapa faktor yang perlu dipertimbangkan saa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Apa saja manfaat dari teknologi telematika pad...</td>\n",
       "      <td>Teknologi telematika pada kendaraan memiliki b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Bagaimana cara merawat kulit wajah agar tetap ...</td>\n",
       "      <td>Beberapa cara yang dapat dilakukan untuk meraw...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Bagaimana cara merawat rambut agar tetap sehat?</td>\n",
       "      <td>Beberapa cara yang dapat dilakukan untuk meraw...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Apa penyebab turunnya omzet penjualan bunga hi...   \n",
       "1    Apa yang dilakukan pendaki gunung untuk memper...   \n",
       "2       Mengapa nama kerta api Empu Jaya akan diganti?   \n",
       "3    Apa penyebab terjadinya kelangkaan minyak di b...   \n",
       "4                        Mengapa Muchyar Yara dihukum?   \n",
       "..                                                 ...   \n",
       "595              Mengapa mobil otonom menjadi populer?   \n",
       "596       Bagaimana cara memilih oli mesin yang tepat?   \n",
       "597  Apa saja manfaat dari teknologi telematika pad...   \n",
       "598  Bagaimana cara merawat kulit wajah agar tetap ...   \n",
       "599    Bagaimana cara merawat rambut agar tetap sehat?   \n",
       "\n",
       "                                                answer answer_pad kandidat  \\\n",
       "0    Enjang, seorang pedagang bunga, menduga penuru...                       \n",
       "1    Bagi yang mempunyai hobi mendaki gunung, merek...                       \n",
       "2    Usut punya usut, nama Empu Jaya dianggap terla...                       \n",
       "3    Penyebabnya adalah kepanikan warga atas rencan...                       \n",
       "4    Dia diberi sanksi lantaran mengkritik kepemimp...                       \n",
       "..                                                 ...        ...      ...   \n",
       "595  Mobil otonom menjadi populer karena dapat meni...                       \n",
       "596  Beberapa faktor yang perlu dipertimbangkan saa...                       \n",
       "597  Teknologi telematika pada kendaraan memiliki b...                       \n",
       "598  Beberapa cara yang dapat dilakukan untuk meraw...                       \n",
       "599  Beberapa cara yang dapat dilakukan untuk meraw...                       \n",
       "\n",
       "    kandidat_pad bad_answer  \n",
       "0                            \n",
       "1                            \n",
       "2                            \n",
       "3                            \n",
       "4                            \n",
       "..           ...        ...  \n",
       "595                          \n",
       "596                          \n",
       "597                          \n",
       "598                          \n",
       "599                          \n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(dataset_final)\n",
    "df['answer_pad']=''\n",
    "df['kandidat']\t=''\n",
    "df['kandidat_pad']=''\n",
    "df['bad_answer']=''\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f96054",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:06.702618Z",
     "iopub.status.busy": "2023-12-22T09:07:06.702354Z",
     "iopub.status.idle": "2023-12-22T09:07:07.098423Z",
     "shell.execute_reply": "2023-12-22T09:07:07.097523Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.412572,
     "end_time": "2023-12-22T09:07:07.101024",
     "exception": false,
     "start_time": "2023-12-22T09:07:06.688452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_pad</th>\n",
       "      <th>kandidat</th>\n",
       "      <th>kandidat_pad</th>\n",
       "      <th>bad_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[apa, penyebab, turunnya, omzet, penjualan, bu...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[apa, yang, dilakukan, pendaki, gunung, untuk,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mengapa, nama, kerta, api, empu, jaya, akan, ...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apa, penyebab, terjadinya, kelangkaan, minyak...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mengapa, muchyar, yara, dihukum]</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  [apa, penyebab, turunnya, omzet, penjualan, bu...   \n",
       "1  [apa, yang, dilakukan, pendaki, gunung, untuk,...   \n",
       "2  [mengapa, nama, kerta, api, empu, jaya, akan, ...   \n",
       "3  [apa, penyebab, terjadinya, kelangkaan, minyak...   \n",
       "4                  [mengapa, muchyar, yara, dihukum]   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...   \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...   \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...   \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...   \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...   \n",
       "\n",
       "                                          answer_pad kandidat kandidat_pad  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...                         \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...                         \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...                         \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...                         \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...                         \n",
       "\n",
       "  bad_answer  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index,'question'] = gensim.utils.simple_preprocess(row['question'])\n",
    "    df.at[index,'answer'] = gensim.utils.simple_preprocess(row['answer'])\n",
    "    df.at[index,'answer_pad'] = gensim.utils.simple_preprocess(row['answer'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6062f37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.129687Z",
     "iopub.status.busy": "2023-12-22T09:07:07.129353Z",
     "iopub.status.idle": "2023-12-22T09:07:07.149479Z",
     "shell.execute_reply": "2023-12-22T09:07:07.148630Z"
    },
    "papermill": {
     "duration": 0.03643,
     "end_time": "2023-12-22T09:07:07.151468",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.115038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in range(0, 600, 20):\n",
    "    group = list(range(i, i+20))\n",
    "    data_list.append(group)\n",
    "new_data=[['']]*600\n",
    "for i in range(0,600):\n",
    "    x = math.ceil((i+1)/20)\n",
    "    y = x-1\n",
    "    new_data[i]=data_list[y]\n",
    "heil = pd.DataFrame(columns=['kelompok'],index=range(len(new_data)))\n",
    "for i in range(len(new_data)):\n",
    "  heil.at[i,'kelompok']= new_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd08dd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.179235Z",
     "iopub.status.busy": "2023-12-22T09:07:07.178930Z",
     "iopub.status.idle": "2023-12-22T09:07:07.183985Z",
     "shell.execute_reply": "2023-12-22T09:07:07.183165Z"
    },
    "papermill": {
     "duration": 0.021081,
     "end_time": "2023-12-22T09:07:07.185870",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.164789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tukar(lists,cari):\n",
    "  salinan = lists[:]\n",
    "  if cari in salinan:\n",
    "    index = salinan.index(cari)\n",
    "    if index == 0:\n",
    "      return salinan\n",
    "    else:\n",
    "      salinan[0],salinan[index] = salinan[index],salinan[0]\n",
    "      return salinan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30217da1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.214472Z",
     "iopub.status.busy": "2023-12-22T09:07:07.214204Z",
     "iopub.status.idle": "2023-12-22T09:07:07.383174Z",
     "shell.execute_reply": "2023-12-22T09:07:07.382295Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.186348,
     "end_time": "2023-12-22T09:07:07.385490",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.199142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kelompok</th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 11, 9, 15, 8, 7, 10, 6, 19, 17, 5, 1, 13, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 11, 0, 9, 18, 14, 16, 12, 15, 8, 13, 7, 17...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 0, 12, 17, 14, 3, 19, 6, 4, 9, 10, 8, 15, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3, 16, 19, 1, 6, 14, 2, 11, 7, 4, 18, 15, 13,...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 2, 17, 3, 19, 0, 18, 13, 7, 10, 5, 9, 1, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            kelompok bad good\n",
       "0  [0, 11, 9, 15, 8, 7, 10, 6, 19, 17, 5, 1, 13, ...   1    0\n",
       "1  [1, 11, 0, 9, 18, 14, 16, 12, 15, 8, 13, 7, 17...   0    1\n",
       "2  [2, 0, 12, 17, 14, 3, 19, 6, 4, 9, 10, 8, 15, ...   1    2\n",
       "3  [3, 16, 19, 1, 6, 14, 2, 11, 7, 4, 18, 15, 13,...   1    3\n",
       "4  [4, 2, 17, 3, 19, 0, 18, 13, 7, 10, 5, 9, 1, 1...   1    4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "for index,row in heil.iterrows():\n",
    "  heil.at[index,'kelompok'] = tukar(row['kelompok'],index)\n",
    "heil['bad']=''\n",
    "heil['good']=''\n",
    "for index,row in heil.iterrows():\n",
    "  heil.at[index,'kelompok'] = [row['kelompok'][0]]+ random.sample(row['kelompok'][1:],len(row['kelompok'])-1)\n",
    "  heil.at[index,'bad']=int(row['kelompok'][1])\n",
    "  heil.at[index,'good']=int(row['kelompok'][0])\n",
    "heil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9cc55c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.414124Z",
     "iopub.status.busy": "2023-12-22T09:07:07.413840Z",
     "iopub.status.idle": "2023-12-22T09:07:07.418232Z",
     "shell.execute_reply": "2023-12-22T09:07:07.417324Z"
    },
    "papermill": {
     "duration": 0.020855,
     "end_time": "2023-12-22T09:07:07.420210",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.399355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kandidat(baris):\n",
    "    text =[]\n",
    "    for i in baris:\n",
    "        text.append(df['answer'][i])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238041d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.448324Z",
     "iopub.status.busy": "2023-12-22T09:07:07.447659Z",
     "iopub.status.idle": "2023-12-22T09:07:07.623785Z",
     "shell.execute_reply": "2023-12-22T09:07:07.623020Z"
    },
    "papermill": {
     "duration": 0.192364,
     "end_time": "2023-12-22T09:07:07.625920",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.433556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "heil['kandidat'] = ''\n",
    "for index,row in heil.iterrows():\n",
    "    heil.at[index,'kandidat']=kandidat(row['kelompok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b630ea",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.695468Z",
     "iopub.status.busy": "2023-12-22T09:07:07.695133Z",
     "iopub.status.idle": "2023-12-22T09:07:07.802802Z",
     "shell.execute_reply": "2023-12-22T09:07:07.801924Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.124514,
     "end_time": "2023-12-22T09:07:07.804990",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.680476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kelompok</th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>kandidat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 11, 9, 15, 8, 7, 10, 6, 19, 17, 5, 1, 13, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[enjang, seorang, pedagang, bunga, menduga, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 11, 0, 9, 18, 14, 16, 12, 15, 8, 13, 7, 17...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[bagi, yang, mempunyai, hobi, mendaki, gunung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 0, 12, 17, 14, 3, 19, 6, 4, 9, 10, 8, 15, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[usut, punya, usut, nama, empu, jaya, diangga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3, 16, 19, 1, 6, 14, 2, 11, 7, 4, 18, 15, 13,...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[penyebabnya, adalah, kepanikan, warga, atas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 2, 17, 3, 19, 0, 18, 13, 7, 10, 5, 9, 1, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[dia, diberi, sanksi, lantaran, mengkritik, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[595, 580, 596, 584, 592, 594, 583, 581, 590, ...</td>\n",
       "      <td>581</td>\n",
       "      <td>595</td>\n",
       "      <td>[[mobil, otonom, menjadi, populer, karena, dap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[596, 598, 597, 588, 586, 584, 580, 592, 591, ...</td>\n",
       "      <td>581</td>\n",
       "      <td>596</td>\n",
       "      <td>[[beberapa, faktor, yang, perlu, dipertimbangk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[597, 599, 590, 585, 592, 598, 582, 586, 596, ...</td>\n",
       "      <td>581</td>\n",
       "      <td>597</td>\n",
       "      <td>[[teknologi, telematika, pada, kendaraan, memi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[598, 599, 586, 585, 580, 595, 589, 596, 592, ...</td>\n",
       "      <td>581</td>\n",
       "      <td>598</td>\n",
       "      <td>[[beberapa, cara, yang, dapat, dilakukan, untu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[599, 592, 593, 581, 582, 594, 590, 585, 584, ...</td>\n",
       "      <td>581</td>\n",
       "      <td>599</td>\n",
       "      <td>[[beberapa, cara, yang, dapat, dilakukan, untu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              kelompok  bad good  \\\n",
       "0    [0, 11, 9, 15, 8, 7, 10, 6, 19, 17, 5, 1, 13, ...    1    0   \n",
       "1    [1, 11, 0, 9, 18, 14, 16, 12, 15, 8, 13, 7, 17...    0    1   \n",
       "2    [2, 0, 12, 17, 14, 3, 19, 6, 4, 9, 10, 8, 15, ...    1    2   \n",
       "3    [3, 16, 19, 1, 6, 14, 2, 11, 7, 4, 18, 15, 13,...    1    3   \n",
       "4    [4, 2, 17, 3, 19, 0, 18, 13, 7, 10, 5, 9, 1, 1...    1    4   \n",
       "..                                                 ...  ...  ...   \n",
       "595  [595, 580, 596, 584, 592, 594, 583, 581, 590, ...  581  595   \n",
       "596  [596, 598, 597, 588, 586, 584, 580, 592, 591, ...  581  596   \n",
       "597  [597, 599, 590, 585, 592, 598, 582, 586, 596, ...  581  597   \n",
       "598  [598, 599, 586, 585, 580, 595, 589, 596, 592, ...  581  598   \n",
       "599  [599, 592, 593, 581, 582, 594, 590, 585, 584, ...  581  599   \n",
       "\n",
       "                                              kandidat  \n",
       "0    [[enjang, seorang, pedagang, bunga, menduga, p...  \n",
       "1    [[bagi, yang, mempunyai, hobi, mendaki, gunung...  \n",
       "2    [[usut, punya, usut, nama, empu, jaya, diangga...  \n",
       "3    [[penyebabnya, adalah, kepanikan, warga, atas,...  \n",
       "4    [[dia, diberi, sanksi, lantaran, mengkritik, k...  \n",
       "..                                                 ...  \n",
       "595  [[mobil, otonom, menjadi, populer, karena, dap...  \n",
       "596  [[beberapa, faktor, yang, perlu, dipertimbangk...  \n",
       "597  [[teknologi, telematika, pada, kendaraan, memi...  \n",
       "598  [[beberapa, cara, yang, dapat, dilakukan, untu...  \n",
       "599  [[beberapa, cara, yang, dapat, dilakukan, untu...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f7150fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.835940Z",
     "iopub.status.busy": "2023-12-22T09:07:07.835658Z",
     "iopub.status.idle": "2023-12-22T09:07:07.841159Z",
     "shell.execute_reply": "2023-12-22T09:07:07.839405Z"
    },
    "papermill": {
     "duration": 0.023156,
     "end_time": "2023-12-22T09:07:07.843362",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.820206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['kandidat']=heil['kandidat']\n",
    "df['kandidat_pad']=heil['kandidat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18196c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.873538Z",
     "iopub.status.busy": "2023-12-22T09:07:07.873241Z",
     "iopub.status.idle": "2023-12-22T09:07:07.951195Z",
     "shell.execute_reply": "2023-12-22T09:07:07.950573Z"
    },
    "papermill": {
     "duration": 0.094649,
     "end_time": "2023-12-22T09:07:07.953069",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.858420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "  df.at[index,'bad_answer'] = df['answer'][heil['bad'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab8188e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:07.981329Z",
     "iopub.status.busy": "2023-12-22T09:07:07.981069Z",
     "iopub.status.idle": "2023-12-22T09:07:08.084493Z",
     "shell.execute_reply": "2023-12-22T09:07:08.083671Z"
    },
    "papermill": {
     "duration": 0.119936,
     "end_time": "2023-12-22T09:07:08.086585",
     "exception": false,
     "start_time": "2023-12-22T09:07:07.966649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_pad</th>\n",
       "      <th>kandidat</th>\n",
       "      <th>kandidat_pad</th>\n",
       "      <th>bad_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[apa, penyebab, turunnya, omzet, penjualan, bu...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td>[[enjang, seorang, pedagang, bunga, menduga, p...</td>\n",
       "      <td>[[enjang, seorang, pedagang, bunga, menduga, p...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[apa, yang, dilakukan, pendaki, gunung, untuk,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td>[[bagi, yang, mempunyai, hobi, mendaki, gunung...</td>\n",
       "      <td>[[bagi, yang, mempunyai, hobi, mendaki, gunung...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mengapa, nama, kerta, api, empu, jaya, akan, ...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td>[[usut, punya, usut, nama, empu, jaya, diangga...</td>\n",
       "      <td>[[usut, punya, usut, nama, empu, jaya, diangga...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apa, penyebab, terjadinya, kelangkaan, minyak...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td>[[penyebabnya, adalah, kepanikan, warga, atas,...</td>\n",
       "      <td>[[penyebabnya, adalah, kepanikan, warga, atas,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mengapa, muchyar, yara, dihukum]</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td>[[dia, diberi, sanksi, lantaran, mengkritik, k...</td>\n",
       "      <td>[[dia, diberi, sanksi, lantaran, mengkritik, k...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  [apa, penyebab, turunnya, omzet, penjualan, bu...   \n",
       "1  [apa, yang, dilakukan, pendaki, gunung, untuk,...   \n",
       "2  [mengapa, nama, kerta, api, empu, jaya, akan, ...   \n",
       "3  [apa, penyebab, terjadinya, kelangkaan, minyak...   \n",
       "4                  [mengapa, muchyar, yara, dihukum]   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...   \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...   \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...   \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...   \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...   \n",
       "\n",
       "                                          answer_pad  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...   \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...   \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...   \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...   \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...   \n",
       "\n",
       "                                            kandidat  \\\n",
       "0  [[enjang, seorang, pedagang, bunga, menduga, p...   \n",
       "1  [[bagi, yang, mempunyai, hobi, mendaki, gunung...   \n",
       "2  [[usut, punya, usut, nama, empu, jaya, diangga...   \n",
       "3  [[penyebabnya, adalah, kepanikan, warga, atas,...   \n",
       "4  [[dia, diberi, sanksi, lantaran, mengkritik, k...   \n",
       "\n",
       "                                        kandidat_pad  \\\n",
       "0  [[enjang, seorang, pedagang, bunga, menduga, p...   \n",
       "1  [[bagi, yang, mempunyai, hobi, mendaki, gunung...   \n",
       "2  [[usut, punya, usut, nama, empu, jaya, diangga...   \n",
       "3  [[penyebabnya, adalah, kepanikan, warga, atas,...   \n",
       "4  [[dia, diberi, sanksi, lantaran, mengkritik, k...   \n",
       "\n",
       "                                          bad_answer  \n",
       "0  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "1  [enjang, seorang, pedagang, bunga, menduga, pe...  \n",
       "2  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "3  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "4  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59847346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.117555Z",
     "iopub.status.busy": "2023-12-22T09:07:08.117263Z",
     "iopub.status.idle": "2023-12-22T09:07:08.122046Z",
     "shell.execute_reply": "2023-12-22T09:07:08.121244Z"
    },
    "papermill": {
     "duration": 0.021924,
     "end_time": "2023-12-22T09:07:08.123899",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.101975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list2text(data):\n",
    "  listing = []\n",
    "  for i in range(len(data)):\n",
    "    kalimat = ' '.join([str(item) for item in data[i]])\n",
    "    listing.append(kalimat)\n",
    "    # listing.append(kalimat)\n",
    "  return listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1efebfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.153499Z",
     "iopub.status.busy": "2023-12-22T09:07:08.153221Z",
     "iopub.status.idle": "2023-12-22T09:07:08.157143Z",
     "shell.execute_reply": "2023-12-22T09:07:08.156451Z"
    },
    "papermill": {
     "duration": 0.020878,
     "end_time": "2023-12-22T09:07:08.159098",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.138220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cekmax(data):\n",
    "    dat = data.str.len().max()\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017275d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.188296Z",
     "iopub.status.busy": "2023-12-22T09:07:08.188035Z",
     "iopub.status.idle": "2023-12-22T09:07:08.195138Z",
     "shell.execute_reply": "2023-12-22T09:07:08.194225Z"
    },
    "papermill": {
     "duration": 0.024298,
     "end_time": "2023-12-22T09:07:08.197503",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.173205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " panjang pertanyaan : 14, panjang jawaban : 57\n"
     ]
    }
   ],
   "source": [
    "pertanyaan = cekmax(df[\"question\"])\n",
    "jawaban = cekmax(df[\"answer\"])\n",
    "print(\" panjang pertanyaan : \"+str(pertanyaan)+\",\"+\" panjang jawaban : \"+str(jawaban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b6bce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.230343Z",
     "iopub.status.busy": "2023-12-22T09:07:08.230060Z",
     "iopub.status.idle": "2023-12-22T09:07:08.236232Z",
     "shell.execute_reply": "2023-12-22T09:07:08.235316Z"
    },
    "papermill": {
     "duration": 0.024482,
     "end_time": "2023-12-22T09:07:08.238263",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.213781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padding(data,atr,length):\n",
    "  if atr == 'kandidat_pad':\n",
    "    for i, kandidat in enumerate(data[atr]):\n",
    "      al = []\n",
    "      for j in kandidat:\n",
    "        # print(len(j))\n",
    "        j+=['<PAD>']*(length-len(j))\n",
    "        al.append(j)\n",
    "      data.at[i,atr] = al\n",
    "  else:\n",
    "    for i in range(len(data)):\n",
    "      data.at[i,atr]+=['<PAD>']*(length-len(data.at[i,atr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8892222a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.269203Z",
     "iopub.status.busy": "2023-12-22T09:07:08.268943Z",
     "iopub.status.idle": "2023-12-22T09:07:08.560161Z",
     "shell.execute_reply": "2023-12-22T09:07:08.559204Z"
    },
    "papermill": {
     "duration": 0.308781,
     "end_time": "2023-12-22T09:07:08.562330",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.253549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_pad</th>\n",
       "      <th>kandidat</th>\n",
       "      <th>kandidat_pad</th>\n",
       "      <th>bad_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[apa, penyebab, turunnya, omzet, penjualan, bu...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "      <td>[[enjang, seorang, pedagang, bunga, menduga, p...</td>\n",
       "      <td>[[enjang, seorang, pedagang, bunga, menduga, p...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[apa, yang, dilakukan, pendaki, gunung, untuk,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "      <td>[[bagi, yang, mempunyai, hobi, mendaki, gunung...</td>\n",
       "      <td>[[bagi, yang, mempunyai, hobi, mendaki, gunung...</td>\n",
       "      <td>[enjang, seorang, pedagang, bunga, menduga, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mengapa, nama, kerta, api, empu, jaya, akan, ...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td>[usut, punya, usut, nama, empu, jaya, dianggap...</td>\n",
       "      <td>[[usut, punya, usut, nama, empu, jaya, diangga...</td>\n",
       "      <td>[[usut, punya, usut, nama, empu, jaya, diangga...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apa, penyebab, terjadinya, kelangkaan, minyak...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td>[penyebabnya, adalah, kepanikan, warga, atas, ...</td>\n",
       "      <td>[[penyebabnya, adalah, kepanikan, warga, atas,...</td>\n",
       "      <td>[[penyebabnya, adalah, kepanikan, warga, atas,...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mengapa, muchyar, yara, dihukum, &lt;PAD&gt;, &lt;PAD&gt;...</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td>[dia, diberi, sanksi, lantaran, mengkritik, ke...</td>\n",
       "      <td>[[dia, diberi, sanksi, lantaran, mengkritik, k...</td>\n",
       "      <td>[[dia, diberi, sanksi, lantaran, mengkritik, k...</td>\n",
       "      <td>[bagi, yang, mempunyai, hobi, mendaki, gunung,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  [apa, penyebab, turunnya, omzet, penjualan, bu...   \n",
       "1  [apa, yang, dilakukan, pendaki, gunung, untuk,...   \n",
       "2  [mengapa, nama, kerta, api, empu, jaya, akan, ...   \n",
       "3  [apa, penyebab, terjadinya, kelangkaan, minyak...   \n",
       "4  [mengapa, muchyar, yara, dihukum, <PAD>, <PAD>...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...   \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...   \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...   \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...   \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...   \n",
       "\n",
       "                                          answer_pad  \\\n",
       "0  [enjang, seorang, pedagang, bunga, menduga, pe...   \n",
       "1  [bagi, yang, mempunyai, hobi, mendaki, gunung,...   \n",
       "2  [usut, punya, usut, nama, empu, jaya, dianggap...   \n",
       "3  [penyebabnya, adalah, kepanikan, warga, atas, ...   \n",
       "4  [dia, diberi, sanksi, lantaran, mengkritik, ke...   \n",
       "\n",
       "                                            kandidat  \\\n",
       "0  [[enjang, seorang, pedagang, bunga, menduga, p...   \n",
       "1  [[bagi, yang, mempunyai, hobi, mendaki, gunung...   \n",
       "2  [[usut, punya, usut, nama, empu, jaya, diangga...   \n",
       "3  [[penyebabnya, adalah, kepanikan, warga, atas,...   \n",
       "4  [[dia, diberi, sanksi, lantaran, mengkritik, k...   \n",
       "\n",
       "                                        kandidat_pad  \\\n",
       "0  [[enjang, seorang, pedagang, bunga, menduga, p...   \n",
       "1  [[bagi, yang, mempunyai, hobi, mendaki, gunung...   \n",
       "2  [[usut, punya, usut, nama, empu, jaya, diangga...   \n",
       "3  [[penyebabnya, adalah, kepanikan, warga, atas,...   \n",
       "4  [[dia, diberi, sanksi, lantaran, mengkritik, k...   \n",
       "\n",
       "                                          bad_answer  \n",
       "0  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "1  [enjang, seorang, pedagang, bunga, menduga, pe...  \n",
       "2  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "3  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  \n",
       "4  [bagi, yang, mempunyai, hobi, mendaki, gunung,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding(df,'question',15)\n",
    "padding(df,'answer_pad',60)\n",
    "padding(df,'bad_answer',60)\n",
    "padding(df,'kandidat_pad',60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f419c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.595382Z",
     "iopub.status.busy": "2023-12-22T09:07:08.595119Z",
     "iopub.status.idle": "2023-12-22T09:07:08.960837Z",
     "shell.execute_reply": "2023-12-22T09:07:08.959709Z"
    },
    "papermill": {
     "duration": 0.383832,
     "end_time": "2023-12-22T09:07:08.962918",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.579086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sukses\n"
     ]
    }
   ],
   "source": [
    "df.to_json(\"//kaggle/working//after prepro 2.json\")\n",
    "print('sukses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff7eb643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:08.993382Z",
     "iopub.status.busy": "2023-12-22T09:07:08.993091Z",
     "iopub.status.idle": "2023-12-22T09:07:09.010488Z",
     "shell.execute_reply": "2023-12-22T09:07:09.009611Z"
    },
    "papermill": {
     "duration": 0.034634,
     "end_time": "2023-12-22T09:07:09.012326",
     "exception": false,
     "start_time": "2023-12-22T09:07:08.977692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kalimat = []\n",
    "for i in range(len(df)):\n",
    "  kalimat.append(df['question'][i])\n",
    "  kalimat.append(df['answer_pad'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51f5c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:09.042214Z",
     "iopub.status.busy": "2023-12-22T09:07:09.041941Z",
     "iopub.status.idle": "2023-12-22T09:07:13.171549Z",
     "shell.execute_reply": "2023-12-22T09:07:13.170839Z"
    },
    "papermill": {
     "duration": 4.147156,
     "end_time": "2023-12-22T09:07:13.173854",
     "exception": false,
     "start_time": "2023-12-22T09:07:09.026698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(sentences=kalimat,vector_size=100, window=8, min_count=1,sg=1, workers=8,alpha=0.025,min_alpha=0.0001)\n",
    "model_w2v.train(kalimat, total_examples=len(kalimat), compute_loss=True, epochs=50,)\n",
    "model_w2v.wv.save_word2vec_format(\"/kaggle/working/word2vec 2nd.model\",binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c77faa",
   "metadata": {
    "papermill": {
     "duration": 0.014445,
     "end_time": "2023-12-22T09:07:13.203283",
     "exception": false,
     "start_time": "2023-12-22T09:07:13.188838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pakai ini ketika sudah pernah melakukan preprocessing sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aadeac51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:13.235425Z",
     "iopub.status.busy": "2023-12-22T09:07:13.235118Z",
     "iopub.status.idle": "2023-12-22T09:07:14.024229Z",
     "shell.execute_reply": "2023-12-22T09:07:14.023267Z"
    },
    "papermill": {
     "duration": 0.807862,
     "end_time": "2023-12-22T09:07:14.026558",
     "exception": false,
     "start_time": "2023-12-22T09:07:13.218696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(after_prepro)\n",
    "model_w2v = KeyedVectors.load_word2vec_format(word2vecModel,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e4567a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:14.057793Z",
     "iopub.status.busy": "2023-12-22T09:07:14.057506Z",
     "iopub.status.idle": "2023-12-22T09:07:14.108478Z",
     "shell.execute_reply": "2023-12-22T09:07:14.107837Z"
    },
    "papermill": {
     "duration": 0.06892,
     "end_time": "2023-12-22T09:07:14.110559",
     "exception": false,
     "start_time": "2023-12-22T09:07:14.041639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kandidat = []\n",
    "kandidat_pad = []\n",
    "question = []\n",
    "answer = []\n",
    "bad_answer = []\n",
    "for i, j in df.iterrows():\n",
    "  kandidat.append(j['kandidat'])\n",
    "  kandidat_pad.append(j['kandidat_pad'])\n",
    "  question.append(j['question'])\n",
    "  answer.append(j['answer_pad'])\n",
    "  bad_answer.append(j['bad_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b22fb10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:14.140690Z",
     "iopub.status.busy": "2023-12-22T09:07:14.140099Z",
     "iopub.status.idle": "2023-12-22T09:07:14.418875Z",
     "shell.execute_reply": "2023-12-22T09:07:14.418087Z"
    },
    "papermill": {
     "duration": 0.296398,
     "end_time": "2023-12-22T09:07:14.421242",
     "exception": false,
     "start_time": "2023-12-22T09:07:14.124844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_filter = []\n",
    "answer_filter=[]\n",
    "bad_answer_filter = []\n",
    "kandidat_pad_filter =[]\n",
    "for c in question:\n",
    "  word_filter=[]\n",
    "  for word in c:\n",
    "    # if word in model_w2v.vocab:\n",
    "    if word in model_w2v.key_to_index:\n",
    "      word_filter.append(word)\n",
    "  if len(word_filter) != 0:\n",
    "    question_filter.append(word_filter)\n",
    "\n",
    "for c in answer:\n",
    "  word_filter=[]\n",
    "  for word in c:\n",
    "    if word in model_w2v.key_to_index:\n",
    "      word_filter.append(word)\n",
    "  if len(word_filter) != 0:\n",
    "    answer_filter.append(word_filter)\n",
    "for c in bad_answer:\n",
    "  word_filter=[]\n",
    "  for word in c:\n",
    "    if word in model_w2v.key_to_index:\n",
    "      word_filter.append(word)\n",
    "  if len(word_filter) != 0:\n",
    "    bad_answer_filter.append(word_filter)\n",
    "def filtering_words(words):\n",
    "  filtered=[]\n",
    "  for c in words:\n",
    "    word_filter=[]\n",
    "    for word in c:\n",
    "      if word in model_w2v.key_to_index:\n",
    "        word_filter.append(word)\n",
    "    if len(word_filter)!=0:\n",
    "      filtered.append(word_filter)\n",
    "  return filtered\n",
    "for c in kandidat_pad:\n",
    "  filtering = []\n",
    "  for d in c:\n",
    "    word_filter=[]\n",
    "    for word in d:\n",
    "      if word in model_w2v.key_to_index:\n",
    "        word_filter.append(word)\n",
    "    if len(word_filter) != 0:\n",
    "      filtering.append(word_filter)\n",
    "  if len(filtering)!=0:\n",
    "    kandidat_pad_filter.append(filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2c75ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:14.451528Z",
     "iopub.status.busy": "2023-12-22T09:07:14.451242Z",
     "iopub.status.idle": "2023-12-22T09:07:14.456714Z",
     "shell.execute_reply": "2023-12-22T09:07:14.455878Z"
    },
    "papermill": {
     "duration": 0.022782,
     "end_time": "2023-12-22T09:07:14.458708",
     "exception": false,
     "start_time": "2023-12-22T09:07:14.435926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_bad = []\n",
    "for x in bad_answer_filter:\n",
    "  new = x +['<PAD>']*(60-len(x))\n",
    "  new_bad.append(new)\n",
    "bad_answer_filter = new_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2c208ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:14.488581Z",
     "iopub.status.busy": "2023-12-22T09:07:14.488081Z",
     "iopub.status.idle": "2023-12-22T09:07:15.931733Z",
     "shell.execute_reply": "2023-12-22T09:07:15.930729Z"
    },
    "papermill": {
     "duration": 1.461286,
     "end_time": "2023-12-22T09:07:15.934227",
     "exception": false,
     "start_time": "2023-12-22T09:07:14.472941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_vector = []\n",
    "answer_vector = []\n",
    "badanswer_vector = []\n",
    "kandidat_pad_vector = []\n",
    "for c in question_filter:\n",
    "  question_vector.extend([model_w2v[word] for word in c])\n",
    "for c in answer_filter:\n",
    "  answer_vector.extend([model_w2v[word] for word in c])\n",
    "for c in bad_answer_filter:\n",
    "  badanswer_vector.extend([model_w2v[word] for word in c])\n",
    "for c in kandidat_pad_filter:\n",
    "  filtering = []\n",
    "  for d in c:\n",
    "    filtering.extend([model_w2v[word] for word in d])\n",
    "  kandidat_pad_vector.append(filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9568a70",
   "metadata": {
    "papermill": {
     "duration": 0.017976,
     "end_time": "2023-12-22T09:07:15.967388",
     "exception": false,
     "start_time": "2023-12-22T09:07:15.949412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modifikasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723de9e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.007001Z",
     "iopub.status.busy": "2023-12-22T09:07:16.005837Z",
     "iopub.status.idle": "2023-12-22T09:07:16.141899Z",
     "shell.execute_reply": "2023-12-22T09:07:16.140902Z"
    },
    "papermill": {
     "duration": 0.158547,
     "end_time": "2023-12-22T09:07:16.144823",
     "exception": false,
     "start_time": "2023-12-22T09:07:15.986276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_index =[]\n",
    "answer_index = []\n",
    "badanswer_index = []\n",
    "kandidat_pad_index = []\n",
    "for c in question_filter:\n",
    "  question_index.append([model_w2v.key_to_index[word] for word in c])\n",
    "for c in answer_filter:\n",
    "  answer_index.append([model_w2v.key_to_index[word] for word in c])\n",
    "for c in bad_answer_filter:\n",
    "  badanswer_index.append([model_w2v.key_to_index[word] for word in c])\n",
    "for c in kandidat_pad_filter:\n",
    "  filtering = []\n",
    "  for d in c:\n",
    "    filtering.append([model_w2v.key_to_index[word] for word in d])\n",
    "  kandidat_pad_index.append(filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea98b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.187150Z",
     "iopub.status.busy": "2023-12-22T09:07:16.186817Z",
     "iopub.status.idle": "2023-12-22T09:07:16.254544Z",
     "shell.execute_reply": "2023-12-22T09:07:16.253313Z"
    },
    "papermill": {
     "duration": 0.090979,
     "end_time": "2023-12-22T09:07:16.256841",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.165862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'question':['']*len(df),'answer':['']*len(df),'bad_answer':['']*len(df),'kandidat':['']*len(df)})\n",
    "for i in range(len(df2)):\n",
    "  df2.at[i,'question'] = question_index[i]\n",
    "  df2.at[i,'answer'] = answer_index[i]\n",
    "  df2.at[i,'bad_answer'] = badanswer_index[i]\n",
    "  df2.at[i,'kandidat'] =kandidat_pad_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "788c472a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.289173Z",
     "iopub.status.busy": "2023-12-22T09:07:16.288318Z",
     "iopub.status.idle": "2023-12-22T09:07:16.310805Z",
     "shell.execute_reply": "2023-12-22T09:07:16.309856Z"
    },
    "papermill": {
     "duration": 0.040617,
     "end_time": "2023-12-22T09:07:16.312814",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.272197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrik = np.zeros((len(model_w2v.key_to_index),100))\n",
    "for i in range(len(model_w2v.key_to_index)):\n",
    "  embedding_vector = model_w2v[model_w2v.index_to_key[i]]\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrik[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95cf76a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.344864Z",
     "iopub.status.busy": "2023-12-22T09:07:16.344540Z",
     "iopub.status.idle": "2023-12-22T09:07:16.352286Z",
     "shell.execute_reply": "2023-12-22T09:07:16.351490Z"
    },
    "papermill": {
     "duration": 0.027064,
     "end_time": "2023-12-22T09:07:16.354990",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.327926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df2,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe59309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.390051Z",
     "iopub.status.busy": "2023-12-22T09:07:16.389758Z",
     "iopub.status.idle": "2023-12-22T09:07:16.398267Z",
     "shell.execute_reply": "2023-12-22T09:07:16.397410Z"
    },
    "papermill": {
     "duration": 0.027813,
     "end_time": "2023-12-22T09:07:16.400301",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.372488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_question,train_answer,train_badanswer,test_question,test_answer,test_badanswer,test_kandidat,train_kandidat = [[] for i in range(8)]\n",
    "\n",
    "for i in train_data['question']:\n",
    "  train_question.append(i)\n",
    "for i in train_data['answer']:\n",
    "  train_answer.append(i)\n",
    "for i in train_data['bad_answer']:\n",
    "  train_badanswer.append(i)\n",
    "for i in train_data['kandidat']:\n",
    "  train_kandidat.append(i)\n",
    "for i in test_data['question']:\n",
    "  test_question.append(i)\n",
    "for i in test_data['answer']:\n",
    "  test_answer.append(i)\n",
    "for i in test_data['bad_answer']:\n",
    "  test_badanswer.append(i)\n",
    "for i in test_data['kandidat']:\n",
    "  test_kandidat.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "228fec6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.429963Z",
     "iopub.status.busy": "2023-12-22T09:07:16.429714Z",
     "iopub.status.idle": "2023-12-22T09:07:16.496997Z",
     "shell.execute_reply": "2023-12-22T09:07:16.496202Z"
    },
    "papermill": {
     "duration": 0.084617,
     "end_time": "2023-12-22T09:07:16.499285",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.414668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_question = np.asarray(train_question,dtype=int)\n",
    "train_answer = np.asarray(train_answer,dtype=int)\n",
    "train_badanswer = np.asarray(train_badanswer,dtype=int)\n",
    "train_kandidat = np.asarray(train_kandidat,dtype=int)\n",
    "test_question = np.asarray(test_question,dtype=int)\n",
    "test_answer = np.asarray(test_answer,dtype=int)\n",
    "test_badanswer = np.asarray(test_badanswer,dtype=int)\n",
    "test_kandidat = np.asarray(test_kandidat,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a8a0a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.533378Z",
     "iopub.status.busy": "2023-12-22T09:07:16.533118Z",
     "iopub.status.idle": "2023-12-22T09:07:16.650283Z",
     "shell.execute_reply": "2023-12-22T09:07:16.649379Z"
    },
    "papermill": {
     "duration": 0.134614,
     "end_time": "2023-12-22T09:07:16.652335",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.517721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QaModel():\n",
    "  def __init__(self,units,dropout,optimizers,nama,attentions=False):\n",
    "    self.units=units\n",
    "    self.dropout=dropout\n",
    "    self.optimizers=optimizers\n",
    "    self.nama=nama\n",
    "    self.attentions=attentions\n",
    "\n",
    "  def cosine_similarity(self):\n",
    "    return lambda x: K.batch_dot(x[0], x[1], axes=1) / K.maximum(K.sqrt(K.batch_dot(x[0], x[0]) * K.batch_dot(x[1], x[1])), K.epsilon())\n",
    "\n",
    "  def max_pooling(self,lstm_out):\n",
    "    output = tf.reduce_max(lstm_out, axis=1)\n",
    "    return output\n",
    "  @keras.saving.register_keras_serializable(package=\"my_package\", name=\"custom_loss\")\n",
    "  def custom_loss(self,y_true,y_pred):\n",
    "      return y_pred\n",
    "\n",
    "  @keras.saving.register_keras_serializable(package=\"my_package\", name=\"custom_attention\")\n",
    "  def attention(self,input_q,input_a):\n",
    "    h = self.units*2\n",
    "    w = int(input_q.get_shape()[2]) #panjang dari input untuk tep pertama\n",
    "    h_a = int(input_a.get_shape()[1]) #panjang dari input untuk jawaban\n",
    "    print('w',w)\n",
    "    # print('h_q',h_q)\n",
    "    print('h_a',h_a)\n",
    "    output_q = self.max_pooling(input_q) #maxpooling layer dengan output #(b,w)\n",
    "    print('output_q.shape 0',output_q.shape)\n",
    "\n",
    "    reshape_q = tf.expand_dims(output_q,1) #(b,1,w) mengubah bentuk dari output_q\n",
    "    print('reshape_q.shape 1',reshape_q.shape)\n",
    "    reshape_q = tf.tile(reshape_q,[1,h_a,1]) #(b,h_a,1)\n",
    "    print('reshape_q.shape 2',reshape_q.shape)\n",
    "    reshape_q = tf.reshape(reshape_q,[-1,w]) #(n*h_a,w)\n",
    "    print('reshape_q.shape 3',reshape_q.shape)\n",
    "    reshape_a = tf.reshape(input_a,[-1,w]) #(b*h_a,w)\n",
    "    print('reshape_q.shape 4',reshape_q.shape)\n",
    "\n",
    "    # with tf.name_scope('my_variable',) as scope:\n",
    "    Wam = tf.random.truncated_normal([h,h], stddev=0.1)\n",
    "    Wqm = tf.random.truncated_normal([h,h], stddev=0.1)\n",
    "    Wms = tf.random.truncated_normal([h,1], stddev=0.1)\n",
    "\n",
    "    Wqm = tf.matmul(reshape_q,Wqm)\n",
    "    print('Wqm.shape',Wqm.shape)\n",
    "    Wam = tf.matmul(reshape_a,Wam)\n",
    "    print('Wam.shape',Wam.shape)\n",
    "    Wsum = tf.add(Wqm,Wam)\n",
    "    print('Wsum.shape',Wsum.shape)\n",
    "    M = tf.tanh(Wsum)\n",
    "    print('M 1',M.shape)\n",
    "    M = tf.matmul(M,Wms) #(b*h_a,1)\n",
    "    print('M 2',M.shape)\n",
    "\n",
    "    S = tf.reshape(M,[-1,h_a]) #(b,h_a)\n",
    "    print('S 1',S.shape)\n",
    "    S = tf.nn.softmax(S) #(b,h_a)\n",
    "    print('S 2',S.shape)\n",
    "\n",
    "    S_diag = tf.linalg.diag(S) #(b,h_a,h_a)\n",
    "    print('S_diag',S_diag.shape)\n",
    "    attention_a = tf.matmul(S_diag, input_a) #(b,h_a,w)\n",
    "    print('attention_a',attention_a.shape)\n",
    "\n",
    "    output_a = self.max_pooling(attention_a) #(b,w)\n",
    "    print('output a ',output_a)\n",
    "    return tf.tanh(output_q),tf.tanh(output_a)\n",
    "\n",
    "  def get_bilstm_model(self):\n",
    "    max_question = 15\n",
    "    max_answer = 60\n",
    "    margin=0.1\n",
    "\n",
    "    question = Input(shape=(max_question,),dtype='int32',name='question_base')\n",
    "    answer = Input(shape=(max_answer,), dtype='int32', name='answer')\n",
    "    answer_good = Input(shape=(max_answer,), dtype='int32', name='answer_good_base')\n",
    "    answer_bad = Input(shape=(max_answer,), dtype='int32', name='answer_bad_base')\n",
    "\n",
    "    qa_embedding = Embedding(input_dim=embedding_matrik.shape[0],output_dim=embedding_matrik.shape[1],mask_zero=False,weights=[embedding_matrik],trainable=False)\n",
    "    bilstm = Bidirectional(LSTM(units=self.units, dropout=self.dropout, return_sequences=True))\n",
    "\n",
    "    answer_embedding =qa_embedding(answer)\n",
    "    print('answer embedding 1',answer_embedding.shape)\n",
    "    answer_embedding = bilstm(answer_embedding)\n",
    "    print('bi lstm 1',answer_embedding.shape)\n",
    "\n",
    "    question_embedding =qa_embedding(question)\n",
    "    print('question embedding',question_embedding.shape)\n",
    "    question_embedding = bilstm(question_embedding)\n",
    "    print('bi lstm 2',question_embedding.shape)\n",
    "\n",
    "    if (self.attentions):\n",
    "      q_att,a_att = self.attention(question_embedding,answer_embedding)\n",
    "      print('aatt',a_att.shape)\n",
    "      print('qatt',q_att.shape)\n",
    "      similarity = self.cosine_similarity()\n",
    "      question_answer_similarity = Lambda(similarity)([q_att, a_att])\n",
    "    else:\n",
    "      answer_encoded = self.max_pooling(answer_embedding)\n",
    "      question_encoded = self.max_pooling(question_embedding)\n",
    "      print('ans ',answer_encoded.shape)\n",
    "      print('que',question_encoded.shape)\n",
    "      similarity = self.cosine_similarity()\n",
    "      question_answer_similarity = Lambda(similarity)([question_encoded, answer_encoded])\n",
    "\n",
    "    bilstm_model = Model(name='bilstm',inputs=[question,answer],outputs=question_answer_similarity)\n",
    "    good_similarity = bilstm_model([question,answer_good])\n",
    "    bad_similarity = bilstm_model([question,answer_bad])\n",
    "\n",
    "    loss = Lambda(lambda x: K.relu(margin -x[0]+x[1]),lambda x: x[0])([good_similarity,bad_similarity])\n",
    "\n",
    "\n",
    "    # custom_loss =Lambda(lambda y_true,y_pred:y_pred)\n",
    "\n",
    "    training_model = Model(inputs=[question, answer_good, answer_bad], outputs=loss, name='training_model')\n",
    "    training_model.compile(loss=self.custom_loss, optimizer=self.optimizers, metrics=[\"acc\"])\n",
    "    prediction_model = Model(inputs=[question, answer_good], outputs=good_similarity, name='prediction_model')\n",
    "    prediction_model.compile(loss=self.custom_loss, optimizer=self.optimizers, metrics=[\"acc\"])\n",
    "    return training_model, prediction_model,self.nama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca368c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.682245Z",
     "iopub.status.busy": "2023-12-22T09:07:16.681971Z",
     "iopub.status.idle": "2023-12-22T09:07:16.686370Z",
     "shell.execute_reply": "2023-12-22T09:07:16.685413Z"
    },
    "papermill": {
     "duration": 0.021854,
     "end_time": "2023-12-22T09:07:16.688625",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.666771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = np.full((train_question.shape[0],),0)\n",
    "y = np.full((test_question.shape[0],),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa204295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:16.721327Z",
     "iopub.status.busy": "2023-12-22T09:07:16.721072Z",
     "iopub.status.idle": "2023-12-22T09:07:23.305623Z",
     "shell.execute_reply": "2023-12-22T09:07:23.304655Z"
    },
    "papermill": {
     "duration": 6.602073,
     "end_time": "2023-12-22T09:07:23.308071",
     "exception": false,
     "start_time": "2023-12-22T09:07:16.705998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer embedding 1 (None, 60, 100)\n",
      "bi lstm 1 (None, 60, 150)\n",
      "question embedding (None, 15, 100)\n",
      "bi lstm 2 (None, 15, 150)\n",
      "w 150\n",
      "h_a 60\n",
      "output_q.shape 0 (None, 150)\n",
      "reshape_q.shape 1 (None, 1, 150)\n",
      "reshape_q.shape 2 (None, 60, 150)\n",
      "reshape_q.shape 3 (None, 150)\n",
      "reshape_q.shape 4 (None, 150)\n",
      "Wqm.shape (None, 150)\n",
      "Wam.shape (None, 150)\n",
      "Wsum.shape (None, 150)\n",
      "M 1 (None, 150)\n",
      "M 2 (None, 1)\n",
      "S 1 (None, 60)\n",
      "S 2 (None, 60)\n",
      "S_diag (None, 60, 60)\n",
      "attention_a (None, 60, 150)\n",
      "output a  KerasTensor(type_spec=TensorSpec(shape=(None, 150), dtype=tf.float32, name=None), name='tf.math.reduce_max_1/Max:0', description=\"created by layer 'tf.math.reduce_max_1'\")\n",
      "aatt (None, 150)\n",
      "qatt (None, 150)\n"
     ]
    }
   ],
   "source": [
    "model = QaModel(75,0.1,RMSprop(learning_rate=0.01),'uji terbaik',True)\n",
    "train,predik,nama = model.get_bilstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c07b025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:07:23.340113Z",
     "iopub.status.busy": "2023-12-22T09:07:23.339177Z",
     "iopub.status.idle": "2023-12-22T09:08:17.462272Z",
     "shell.execute_reply": "2023-12-22T09:08:17.461480Z"
    },
    "papermill": {
     "duration": 54.141116,
     "end_time": "2023-12-22T09:08:17.464484",
     "exception": false,
     "start_time": "2023-12-22T09:07:23.323368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 1: val_loss improved from inf to 0.02739, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 18s 266ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 2: val_loss did not improve from 0.02739\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 3: val_loss did not improve from 0.02739\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 4: val_loss improved from 0.02739 to 0.02429, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5: val_loss improved from 0.02429 to 0.02064, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 6: val_loss improved from 0.02064 to 0.01799, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 7: val_loss improved from 0.01799 to 0.01716, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 8: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000    \n",
      "Epoch 9: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.2872e-04 - acc: 1.0000\n",
      "Epoch 10: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 9.1987e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 11: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 12: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.4899e-04 - acc: 1.0000\n",
      "Epoch 13: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 6.6124e-04 - acc: 1.0000\n",
      "Epoch 14: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 6.5494e-04 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.2030e-04 - acc: 1.0000\n",
      "Epoch 15: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.1629e-04 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 6.0657e-04 - acc: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 6.0080e-04 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 3.2838e-04 - acc: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 3.8462e-04 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 8.1927e-04 - acc: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 8.1147e-04 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 7.9494e-04 - acc: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 7.8737e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.2850e-04 - acc: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.2632e-04 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.1066e-04 - acc: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.0675e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.6557e-04 - acc: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.6399e-04 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.2999e-05 - acc: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.2590e-05 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.0293e-04 - acc: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.01716\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 4.0097e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 28: val_loss improved from 0.01716 to 0.01575, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.9122e-04 - acc: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 3.8749e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.4398e-05 - acc: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 9.3499e-05 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.8701e-04 - acc: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 9.7761e-04 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6531e-04 - acc: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.6279e-04 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.6085e-06 - acc: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 9.5170e-06 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.9734e-05 - acc: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.9546e-05 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.7601e-05 - acc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 5.7053e-05 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.3645e-04 - acc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 5.3134e-04 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.0984e-04 - acc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 4.0593e-04 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 8.1015e-05 - acc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 8.0244e-05 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 7.6207e-05 - acc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 7.5482e-05 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.4729e-04 - acc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.4398e-04 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.8342e-04 - acc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.8072e-04 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3367e-04 - acc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.3240e-04 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.7173e-04 - acc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 4.6724e-04 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.6516e-04 - acc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 5.5978e-04 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.2128e-04 - acc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.2012e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.7120e-04 - acc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.6767e-04 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.0951e-04 - acc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 5.0465e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.0674e-04 - acc: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.0477e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.8751e-05 - acc: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.8382e-05 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.7547e-04 - acc: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.7094e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6643e-04 - acc: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.6389e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4898e-04 - acc: 1.0000\n",
      "Epoch 56: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.4756e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6108e-04 - acc: 1.0000\n",
      "Epoch 57: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 3.2198e-04 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.7535e-04 - acc: 1.0000\n",
      "Epoch 58: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.7273e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.0651e-06 - acc: 1.0000\n",
      "Epoch 59: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 8.9787e-06 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.4157e-05 - acc: 1.0000\n",
      "Epoch 60: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 4.3737e-05 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.0332e-04 - acc: 1.0000\n",
      "Epoch 61: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.0138e-04 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.0140e-04 - acc: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.9663e-04 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.0859e-05 - acc: 1.0000\n",
      "Epoch 63: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 8.9994e-05 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.7041e-04 - acc: 1.0000\n",
      "Epoch 64: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.6879e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.8986e-04 - acc: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.01575\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.8805e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.5584e-05 - acc: 1.0000\n",
      "Epoch 66: val_loss improved from 0.01575 to 0.01519, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 5.5054e-05 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6091e-04 - acc: 1.0000\n",
      "Epoch 67: val_loss did not improve from 0.01519\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.5843e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 68: val_loss did not improve from 0.01519\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 6.8577e-05 - acc: 1.0000\n",
      "Epoch 69: val_loss improved from 0.01519 to 0.01510, saving model to /kaggle/working/model terbaik.hdf5\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 6.7924e-05 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.8096e-04 - acc: 1.0000\n",
      "Epoch 70: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.7924e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.5441e-04 - acc: 1.0000\n",
      "Epoch 71: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.5199e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.1768e-05 - acc: 1.0000\n",
      "Epoch 72: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.1561e-05 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3405e-04 - acc: 1.0000\n",
      "Epoch 73: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.3277e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 8.7991e-05 - acc: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 8.7153e-05 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.4930e-04 - acc: 1.0000\n",
      "Epoch 76: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.4598e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 7.8544e-05 - acc: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 7.7796e-05 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 78: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 9.7671e-05 - acc: 1.0000\n",
      "Epoch 79: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 9.6740e-05 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1404e-04 - acc: 1.0000\n",
      "Epoch 80: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.1295e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1571e-04 - acc: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.1461e-04 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.9670e-04 - acc: 1.0000\n",
      "Epoch 83: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.3316e-04 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 8.4132e-05 - acc: 1.0000\n",
      "Epoch 84: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 8.3331e-05 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 85: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5672e-04 - acc: 1.0000\n",
      "Epoch 86: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1.5523e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.6869e-05 - acc: 1.0000\n",
      "Epoch 87: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 3.6518e-05 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 88: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 3.1142e-05 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.7761e-05 - acc: 1.0000\n",
      "Epoch 89: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 3.7401e-05 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 90: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.3394e-04 - acc: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.3171e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.1488e-04 - acc: 1.0000\n",
      "Epoch 92: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.1283e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.6008e-05 - acc: 1.0000\n",
      "Epoch 93: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 2.5761e-05 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 94: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 95: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.0437e-05 - acc: 1.0000\n",
      "Epoch 96: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.9957e-05 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 4.3705e-05 - acc: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.3289e-05 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 98: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 7.9346e-05 - acc: 1.0000\n",
      "Epoch 99: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 7.8590e-05 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.0838e-04 - acc: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.01510\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.0544e-04 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "filename = \"/kaggle/working/model terbaik.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filename,monitor='val_loss',verbose=1, save_best_only=True,save_weights_only=True,mode='min')\n",
    "train.fit([train_question,train_answer,train_badanswer],Y,validation_data=([test_question,test_answer,test_badanswer],y),callbacks=checkpoint,epochs=100)\n",
    "train.save_weights(\"/kaggle/working/train terbaik.h5\", overwrite=True)\n",
    "predik.save_weights(\"/kaggle/working/predik terbaik.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03bd68c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:08:17.627205Z",
     "iopub.status.busy": "2023-12-22T09:08:17.626854Z",
     "iopub.status.idle": "2023-12-22T09:08:17.633203Z",
     "shell.execute_reply": "2023-12-22T09:08:17.632364Z"
    },
    "papermill": {
     "duration": 0.087829,
     "end_time": "2023-12-22T09:08:17.635221",
     "exception": false,
     "start_time": "2023-12-22T09:08:17.547392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filtering_words(words):\n",
    "  filtered=[]\n",
    "  for c in words:\n",
    "    word_filter=[]\n",
    "    for word in c:\n",
    "      if word in model_w2v.key_to_index:\n",
    "        word_filter.append(word)\n",
    "    if len(word_filter)!=0:\n",
    "      filtered.append(word_filter)\n",
    "  return filtered\n",
    "def indexing_words(words):\n",
    "  indexed = []\n",
    "  for c in words:\n",
    "    indexed.append([model_w2v.key_to_index[word] for word in c])\n",
    "  return indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "575c78f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:08:17.791099Z",
     "iopub.status.busy": "2023-12-22T09:08:17.790807Z",
     "iopub.status.idle": "2023-12-22T09:08:17.796852Z",
     "shell.execute_reply": "2023-12-22T09:08:17.795976Z"
    },
    "papermill": {
     "duration": 0.086021,
     "end_time": "2023-12-22T09:08:17.798735",
     "exception": false,
     "start_time": "2023-12-22T09:08:17.712714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QAData():\n",
    "  def __init__(self):\n",
    "    self.model = KeyedVectors.load_word2vec_format(word2vecModel)\n",
    "    self.max_question = 15\n",
    "    self.max_answer = 60\n",
    "  def pad(self, data, length):\n",
    "    return pad_sequences(data, maxlen=length, padding='post', truncating='post', value=0)\n",
    "\n",
    "  def process_test_data(self, question, answers):\n",
    "    answers = self.pad(answers, self.max_answer)\n",
    "    question = self.pad(question, self.max_question)\n",
    "    return question, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e47a049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:08:17.959343Z",
     "iopub.status.busy": "2023-12-22T09:08:17.958984Z",
     "iopub.status.idle": "2023-12-22T09:08:17.965032Z",
     "shell.execute_reply": "2023-12-22T09:08:17.964084Z"
    },
    "papermill": {
     "duration": 0.088887,
     "end_time": "2023-12-22T09:08:17.966956",
     "exception": false,
     "start_time": "2023-12-22T09:08:17.878069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d19f719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:08:18.124079Z",
     "iopub.status.busy": "2023-12-22T09:08:18.123752Z",
     "iopub.status.idle": "2023-12-22T09:09:37.426997Z",
     "shell.execute_reply": "2023-12-22T09:09:37.426204Z"
    },
    "papermill": {
     "duration": 79.38257,
     "end_time": "2023-12-22T09:09:37.428882",
     "exception": false,
     "start_time": "2023-12-22T09:08:18.046312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "c=0\n",
    "c1=0\n",
    "for i in range(len(test_question)):\n",
    "    question = [test_question[i]]*20\n",
    "    answer = test_kandidat[i]\n",
    "    qa_data = QAData()\n",
    "    question_data,answer_data=qa_data.process_test_data(question, answer)\n",
    "    with tf.device('/GPU:0'):\n",
    "        sims = predik.predict([question_data,answer_data])\n",
    "        max_r = np.argmax(sims)\n",
    "        max_n = 0\n",
    "        sim_t = sims[0]\n",
    "        r = rankdata(-sims)\n",
    "        c+=1 if max_r == max_n else 0\n",
    "        c1+=1/float(r[max_n]-r[max_r]+1)\n",
    "MRR = c1/float(len(test_question))\n",
    "MAP = c/float(len(test_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "398aa98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:09:37.643603Z",
     "iopub.status.busy": "2023-12-22T09:09:37.642761Z",
     "iopub.status.idle": "2023-12-22T09:09:37.647803Z",
     "shell.execute_reply": "2023-12-22T09:09:37.646812Z"
    },
    "papermill": {
     "duration": 0.115217,
     "end_time": "2023-12-22T09:09:37.649973",
     "exception": false,
     "start_time": "2023-12-22T09:09:37.534756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai MRR =  0.7735570008241579\n",
      "nilai MAP =  0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "print('nilai MRR = ',MRR)\n",
    "print('nilai MAP = ',MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddac923b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:09:37.862002Z",
     "iopub.status.busy": "2023-12-22T09:09:37.861706Z",
     "iopub.status.idle": "2023-12-22T09:09:37.869535Z",
     "shell.execute_reply": "2023-12-22T09:09:37.868502Z"
    },
    "papermill": {
     "duration": 0.116375,
     "end_time": "2023-12-22T09:09:37.871611",
     "exception": false,
     "start_time": "2023-12-22T09:09:37.755236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20, 60)\n",
      "(600, 15)\n"
     ]
    }
   ],
   "source": [
    "# Menggabungkan array 2D\n",
    "merged_kandidat = np.concatenate((test_kandidat, train_kandidat), axis=0)\n",
    "print(merged_kandidat.shape)\n",
    "merged_question = np.concatenate((test_question, train_question), axis=0)\n",
    "print(merged_question.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68845f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:09:38.082948Z",
     "iopub.status.busy": "2023-12-22T09:09:38.082253Z",
     "iopub.status.idle": "2023-12-22T09:13:58.961354Z",
     "shell.execute_reply": "2023-12-22T09:13:58.960492Z"
    },
    "papermill": {
     "duration": 260.987235,
     "end_time": "2023-12-22T09:13:58.963600",
     "exception": false,
     "start_time": "2023-12-22T09:09:37.976365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "c1=0\n",
    "for i in range(len(merged_question)):\n",
    "    question = [merged_question[i]]*20\n",
    "    answer = merged_kandidat[i]\n",
    "    qa_data = QAData()\n",
    "    question_data,answer_data=qa_data.process_test_data(question, answer)\n",
    "    with tf.device('/GPU:0'):\n",
    "        sims = predik.predict([question_data,answer_data])\n",
    "        max_r = np.argmax(sims)\n",
    "        max_n = 0\n",
    "        sim_t = sims[0]\n",
    "        r = rankdata(-sims)\n",
    "        c+=1 if max_r == max_n else 0\n",
    "        c1+=1/float(r[max_n]-r[max_r]+1)\n",
    "MRR2 = c1/float(len(merged_question))\n",
    "MAP2 = c/float(len(merged_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c7865a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T09:13:59.373888Z",
     "iopub.status.busy": "2023-12-22T09:13:59.373489Z",
     "iopub.status.idle": "2023-12-22T09:13:59.378787Z",
     "shell.execute_reply": "2023-12-22T09:13:59.377810Z"
    },
    "papermill": {
     "duration": 0.217529,
     "end_time": "2023-12-22T09:13:59.381176",
     "exception": false,
     "start_time": "2023-12-22T09:13:59.163647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr :  0.8401663065964534\n",
      "map :  0.7516666666666667\n"
     ]
    }
   ],
   "source": [
    "print('mrr : ', MRR2)\n",
    "print('map : ', MAP2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4207000,
     "sourceId": 7259584,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 441.715293,
   "end_time": "2023-12-22T09:14:02.981995",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-22T09:06:41.266702",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
